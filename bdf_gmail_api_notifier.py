"""
BdFåˆŠè¡Œç‰©ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆGmail APIç‰ˆï¼‰
LesEchos Botã¨åŒã˜æ–¹å¼ã§Gmail APIä½¿ç”¨
"""

import asyncio
import os
import sys
import base64
import time
import json
import schedule
import requests
from pathlib import Path
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
from datetime import datetime, timedelta
import pytz
import logging
from bs4 import BeautifulSoup
import re
from typing import Dict, List, Optional

import google.auth.transport.requests
import google.oauth2.credentials
from googleapiclient.discovery import build
from dotenv import load_dotenv

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# â”€â”€â”€ ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv("credentials/.env", encoding="utf-8-sig")
GMAIL_TO = os.getenv("GMAIL_TO")

# å¿…é ˆãƒã‚§ãƒƒã‚¯
if not GMAIL_TO:
    sys.exit("âŒ credentials/.env ã« GMAIL_TO ãŒã‚ã‚Šã¾ã›ã‚“")

class BdFGmailAPINotifier:
    def __init__(self):
        self.base_url = "https://www.banque-france.fr"
        self.publications_url = f"{self.base_url}/en/publications-and-statistics/publications"
        self.paris_tz = pytz.timezone('Europe/Paris')
        self.data_file = 'bdf_gmail_api_data.json'
        self.gmail_to = GMAIL_TO
        
        # Gmail APIåˆæœŸåŒ–
        self.gmail_service = self.init_gmail()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # å®šæœŸåˆŠè¡Œç‰©ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.publication_patterns = {
            'monthly_business_survey': {
                'title': 'Monthly Business Survey',
                'pattern': r'monthly business survey',
                'priority': 'High'
            },
            'macroeconomic_projections': {
                'title': 'Macroeconomic Projections',
                'pattern': r'macroeconomic projections',
                'priority': 'High'
            },
            'financial_stability_report': {
                'title': 'Financial Stability Report',
                'pattern': r'financial stability report',
                'priority': 'Highest'
            },
            'letter_to_president': {
                'title': 'Letter to the President of the Republic',
                'pattern': r'letter to the president',
                'priority': 'Medium'
            },
            'balance_of_payments': {
                'title': 'Balance of Payments Report',
                'pattern': r'balance of payments.*international investment',
                'priority': 'Medium'
            },
            'observatory_payment_security': {
                'title': 'Observatory Security Payment Report',
                'pattern': r'observatory.*security.*payment',
                'priority': 'Medium'
            },
            'annual_report': {
                'title': 'Banque de France Annual Report',
                'pattern': r'banque de france annual report',
                'priority': 'Medium'
            }
        }
        
        self.load_data()

    def init_gmail(self):
        """Gmail APIåˆæœŸåŒ–ï¼ˆLesEchosæ–¹å¼ï¼‰"""
        SCOPES = ["https://www.googleapis.com/auth/gmail.send"]
        CRED = Path("credentials")
        TOKEN = CRED / "token.json"
        SECRET = CRED / "credentials.json"
        
        try:
            if not TOKEN.exists():
                from google_auth_oauthlib.flow import InstalledAppFlow
                flow = InstalledAppFlow.from_client_secrets_file(SECRET, SCOPES)
                creds = flow.run_local_server(port=0)
                TOKEN.write_text(creds.to_json())
            
            creds = google.oauth2.credentials.Credentials.from_authorized_user_file(TOKEN, SCOPES)
            if creds.expired and creds.refresh_token:
                creds.refresh(google.auth.transport.requests.Request())
                TOKEN.write_text(creds.to_json())
            
            gmail_service = build("gmail", "v1", credentials=creds, cache_discovery=False)
            logger.info("âœ… Gmail API åˆæœŸåŒ–å®Œäº†")
            return gmail_service
            
        except Exception as e:
            logger.error(f"âŒ Gmail API åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error("credentials/credentials.json ãŒæ­£ã—ãé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
            sys.exit(1)

    def load_data(self):
        """éå»ã®åˆŠè¡Œç‰©ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    self.known_publications = json.load(f)
            else:
                self.known_publications = {}
            logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.known_publications)} ä»¶ã®æ—¢çŸ¥åˆŠè¡Œç‰©")
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            self.known_publications = {}

    def save_data(self):
        """ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        try:
            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(self.known_publications, f, ensure_ascii=False, indent=2)
            logger.info("ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†")
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def extract_publications_from_page(self):
        """BdFãƒšãƒ¼ã‚¸ã‹ã‚‰åˆŠè¡Œç‰©ã‚’æŠ½å‡º"""
        try:
            response = self.session.get(self.publications_url, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            publications = []
            
            # HTMLã‹ã‚‰åˆŠè¡Œç‰©ã‚’æ¤œç´¢
            # æ–¹æ³•1: ã‚¿ã‚¤ãƒˆãƒ«ã‚’å«ã‚€è¦ç´ ã‚’æ¤œç´¢
            for element in soup.find_all(['h1', 'h2', 'h3', 'h4', 'a']):
                text = element.get_text(strip=True)
                if text and len(text) > 15:
                    # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒã‚§ãƒƒã‚¯
                    for pub_id, pub_config in self.publication_patterns.items():
                        if re.search(pub_config['pattern'], text, re.IGNORECASE):
                            # æ—¥ä»˜ã‚’æŠ½å‡º
                            date_text = self.extract_date_near_element(element)
                            
                            pub_data = {
                                'pub_id': pub_id,
                                'title': text,
                                'date_text': date_text,
                                'pattern_matched': pub_config['pattern'],
                                'priority': pub_config['priority'],
                                'extracted_at': datetime.now(self.paris_tz).isoformat(),
                                'source_tag': element.name
                            }
                            publications.append(pub_data)
                            break
            
            # æ–¹æ³•2: ãƒšãƒ¼ã‚¸å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚‚æ¤œç´¢
            page_text = soup.get_text()
            for pub_id, pub_config in self.publication_patterns.items():
                matches = list(re.finditer(pub_config['pattern'], page_text, re.IGNORECASE))
                
                for match in matches:
                    # æ—¢ã«è¦‹ã¤ã‹ã£ãŸã‚¿ã‚¤ãƒˆãƒ«ã¨é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    context_start = max(0, match.start() - 200)
                    context_end = min(len(page_text), match.end() + 200)
                    context = page_text[context_start:context_end]
                    
                    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å®Œå…¨ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
                    title = self.extract_title_from_context(context)
                    date_text = self.extract_date_from_context(context)
                    
                    if title and len(title) > 15:
                        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                        is_duplicate = any(
                            pub['title'].lower() == title.lower() 
                            for pub in publications
                        )
                        
                        if not is_duplicate:
                            pub_data = {
                                'pub_id': pub_id,
                                'title': title,
                                'date_text': date_text,
                                'pattern_matched': pub_config['pattern'],
                                'priority': pub_config['priority'],
                                'extracted_at': datetime.now(self.paris_tz).isoformat(),
                                'source_tag': 'text_search'
                            }
                            publications.append(pub_data)
            
            logger.info(f"ãƒšãƒ¼ã‚¸ã‹ã‚‰ {len(publications)} ä»¶ã®åˆŠè¡Œç‰©ã‚’æŠ½å‡º")
            return publications
            
        except Exception as e:
            logger.error(f"ãƒšãƒ¼ã‚¸æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def extract_date_near_element(self, element):
        """è¦ç´ ã®è¿‘ãã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º"""
        # åŒã˜è¦ªè¦ç´ å†…ã‹ã‚‰æ—¥ä»˜ã‚’æ¤œç´¢
        parent = element.parent
        if parent:
            text = parent.get_text()
            return self.extract_date_from_context(text)
        return ''

    def extract_title_from_context(self, context):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å®Œå…¨ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
        lines = context.split('\n')
        for line in lines:
            cleaned = line.strip()
            if len(cleaned) > 20 and len(cleaned) < 200:
                # ç„¡åŠ¹ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å¤–
                if not re.search(r'^(Home|Menu|Search|Filter)', cleaned, re.IGNORECASE):
                    return cleaned
        return ''

    def extract_date_from_context(self, context):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º"""
        date_patterns = [
            r'(\d{1,2}(?:st|nd|rd|th)?\s+of\s+\w+\s+\d{4})',
            r'(\w+\s+\d{1,2}(?:st|nd|rd|th)?,?\s+\d{4})',
            r'(\d{1,2}[/-]\d{1,2}[/-]\d{4})'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, context, re.IGNORECASE)
            if match:
                return match.group(1)
        return ''

    def check_for_new_publications(self):
        """æ–°ã—ã„åˆŠè¡Œç‰©ã‚’ãƒã‚§ãƒƒã‚¯"""
        logger.info("ğŸ” æ–°ã—ã„åˆŠè¡Œç‰©ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        

    def send_gmail_notification(self, matching_publications):
        """Gmail APIçµŒç”±ã§åˆŠè¡Œç‰©é€šçŸ¥ã‚’é€ä¿¡ï¼ˆLesEchosæ–¹å¼ï¼‰"""
        try:
            subject = f"ğŸ¦ BdFåˆŠè¡Œç‰©é€šçŸ¥ - {len(matching_publications)}ä»¶ã®å¯¾è±¡åˆŠè¡Œç‰©"
            
            # HTMLå½¢å¼ã®ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ä½œæˆ
            html_body = self.create_notification_html(matching_publications)
            
            # MIMEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
            msg = MimeMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = self.gmail_to
            msg['To'] = self.gmail_to
            
            # HTMLç‰ˆã‚’æ·»ä»˜
            html_part = MimeText(html_body, 'html', 'utf-8')
            msg.attach(html_part)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            raw_message = base64.urlsafe_b64encode(msg.as_bytes()).decode()
            
            # Gmail APIçµŒç”±ã§é€ä¿¡
            self.gmail_service.users().messages().send(
                userId="me", 
                body={"raw": raw_message}
            ).execute()
            
            logger.info(f"âœ… Gmailé€ä¿¡å®Œäº†: {self.gmail_to}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Gmailé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def create_notification_html(self, matching_publications):
        """HTMLå½¢å¼ã®é€šçŸ¥ãƒ¡ãƒ¼ãƒ«ä½œæˆ"""
        html = f"""
        <html>
        <head>
            <style>
                body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }}
                .header {{ 
                    background-color: #2563eb; 
                    color: white; 
                    padding: 20px; 
                    text-align: center; 
                    border-radius: 8px 8px 0 0;
                }}
                .content {{ padding: 20px; }}
                .publication {{ 
                    border-left: 4px solid #2563eb; 
                    padding: 15px; 
                    margin: 15px 0; 
                    background-color: #f8f9fa; 
                    border-radius: 0 8px 8px 0;
                }}
                .title {{ 
                    font-weight: bold; 
                    font-size: 1.1em; 
                    color: #1f2937; 
                    margin-bottom: 8px;
                }}
                .details {{ 
                    color: #6b7280; 
                    font-size: 0.9em; 
                    line-height: 1.4;
                }}
                .priority-highest {{ border-left-color: #dc2626; }}
                .priority-high {{ border-left-color: #f59e0b; }}
                .priority-medium {{ border-left-color: #10b981; }}
                .footer {{ 
                    background-color: #f3f4f6; 
                    padding: 15px; 
                    margin-top: 20px; 
                    color: #6b7280; 
                    font-size: 0.8em; 
                    border-radius: 8px;
                }}
                .url-link {{
                    color: #2563eb;
                    text-decoration: none;
                    word-break: break-all;
                }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸ¦ Banque de France</h1>
                <h2>å®šæœŸåˆŠè¡Œç‰©ãŒå…¬è¡¨ã•ã‚Œã¾ã—ãŸ</h2>
            </div>
            
            <div class="content">
                <p><strong>{len(matching_publications)}ä»¶</strong>ã®å¯¾è±¡åˆŠè¡Œç‰©ãŒç™ºè¦‹ã•ã‚Œã¾ã—ãŸ:</p>
        """
        
        for i, pub in enumerate(matching_publications, 1):
            priority_class = f"priority-{pub['priority'].lower()}"
            
            html += f"""
                <div class="publication {priority_class}">
                    <div class="title">{i}. {pub['title']}</div>
                    <div class="details">
                        ğŸ“… <strong>ç™ºè¡Œæ—¥:</strong> {pub['date_text'] or 'æ—¥ä»˜ä¸æ˜'}<br>
                        ğŸ”– <strong>ã‚«ãƒ†ã‚´ãƒª:</strong> {self.publication_patterns[pub['pub_id']]['title']}<br>
                        â­ <strong>å„ªå…ˆåº¦:</strong> {pub['priority']}<br>
                        ğŸ• <strong>æ¤œå‡ºæ—¥æ™‚:</strong> {pub['extracted_at'][:19]}<br>
                        ğŸ” <strong>æŠ½å‡ºæ–¹æ³•:</strong> {pub['source_tag']}<br>
                        ğŸ”— <strong>ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:</strong> <a href="{self.publications_url}" class="url-link">{self.publications_url}</a>
                    </div>
                </div>
            """
        
        html += f"""
            </div>
            
            <div class="footer">
                <p><strong>ğŸ¤– BdFåˆŠè¡Œç‰©ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ </strong></p>
                <p>ğŸ“§ é€ä¿¡æ—¥æ™‚: {datetime.now(self.paris_tz).strftime('%Y-%m-%d %H:%M:%S')} (ãƒ‘ãƒªæ™‚é–“)</p>
                <p>ğŸ“Š ç›£è¦–å¯¾è±¡: {len(self.publication_patterns)} ç¨®é¡ã®å®šæœŸåˆŠè¡Œç‰©</p>
                <p>ğŸ”„ ã“ã®ãƒ¡ãƒ¼ãƒ«ã¯è‡ªå‹•é€ä¿¡ã•ã‚Œã¾ã—ãŸã€‚</p>
            </div>
        </body>
        </html>
        """
        
        return html

    def run_daily_check(self):
        """æ—¥æ¬¡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        paris_now = datetime.now(self.paris_tz)
        logger.info(f"ğŸ” æ—¥æ¬¡ãƒã‚§ãƒƒã‚¯é–‹å§‹: {paris_now.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # 8ã‚·ãƒªãƒ¼ã‚ºã®åˆŠè¡Œç‰©ã‚’ãƒã‚§ãƒƒã‚¯
        matching_publications = self.check_for_new_publications()
        
        if matching_publications:
            # å¯¾è±¡ã®åˆŠè¡Œç‰©ãŒè¦‹ã¤ã‹ã£ãŸã‚‰ãƒ¡ãƒ¼ãƒ«é€ä¿¡
            success = self.send_gmail_notification(matching_publications)
            if success:
                logger.info("âœ… åˆŠè¡Œç‰©é€šçŸ¥é€ä¿¡å®Œäº†")
            else:
                logger.error("âŒ é€šçŸ¥é€ä¿¡å¤±æ•—")
        else:
            logger.info("â„¹ï¸ å¯¾è±¡ã®åˆŠè¡Œç‰©ãªã— - é€šçŸ¥é€ä¿¡ãªã—")

    def start_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹"""
        # æ¯æ—¥ãƒ‘ãƒªæ™‚é–“7:00ã«å®Ÿè¡Œ
        schedule.every().day.at("07:00").do(self.run_daily_check)
        
        logger.info("ğŸ“… æ–°åˆŠè¡Œç‰©ãƒã‚§ãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹: æ¯æ—¥ãƒ‘ãƒªæ™‚é–“7:00ã«å®Ÿè¡Œ")
        
        def run_scheduler():
            while True:
                schedule.run_pending()
                time.sleep(60)
        
        import threading
        scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
        scheduler_thread.start()

    def test_notification(self):
        """ãƒ†ã‚¹ãƒˆé€šçŸ¥é€ä¿¡"""
        test_publications = [{
            'pub_id': 'test',
            'title': 'ãƒ†ã‚¹ãƒˆé€šçŸ¥ - BdFåˆŠè¡Œç‰©ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ',
            'date_text': '2025å¹´6æœˆ23æ—¥',
            'priority': 'Test',
            'pattern_matched': 'test',
            'extracted_at': datetime.now(self.paris_tz).isoformat(),
            'source_tag': 'manual_test'
        }]
        
        logger.info("ğŸ§ª ãƒ†ã‚¹ãƒˆé€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã™...")
        success = self.send_gmail_notification(test_publications)
        return success


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ BdFåˆŠè¡Œç‰©ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆGmail APIç‰ˆï¼‰é–‹å§‹")
    print("=" * 60)
    print(f"ğŸ“§ é€šçŸ¥å…ˆ: {GMAIL_TO}")
    print("ğŸ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: credentials/.env")
    print("ğŸ”‘ èªè¨¼: credentials/credentials.json")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    notifier = BdFGmailAPINotifier()
    
    # ãƒ†ã‚¹ãƒˆé€šçŸ¥
    test = input("\nãƒ†ã‚¹ãƒˆé€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower() == 'y'
    if test:
        notifier.test_notification()
    
    # æ‰‹å‹•ãƒã‚§ãƒƒã‚¯
    manual = input("æ‰‹å‹•ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower() == 'y'
    if manual:
        notifier.run_daily_check()
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹
    notifier.start_scheduler()
    
    print(f"\nâœ… ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­")
    print(f"â° è‡ªå‹•ãƒã‚§ãƒƒã‚¯: æ¯æ—¥ãƒ‘ãƒªæ™‚é–“7:00")
    print(f"ğŸ“Š ç›£è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(notifier.publication_patterns)} ç¨®é¡")
    print("\næ‰‹å‹•ãƒã‚§ãƒƒã‚¯: 'm' + Enter")
    print("çµ‚äº†: Ctrl+C")
    
    try:
        while True:
            user_input = input()
            if user_input.lower() == 'm':
                notifier.run_daily_check()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ã‚·ã‚¹ãƒ†ãƒ åœæ­¢")


if __name__ == "__main__":
    main()